<h2 align="left">Driver Gaze Predictor</h2>

![Demo](demo.gif)

## Описание:

Модель для определения направления взгляда водителя. 
Возможные входные данные:
    - Путь к изображению (run_frame.py);
    - Путь к видео (run_video.py);
    - Изображения с веб-камеры для запуска в режиме реального времени (run_webcam).

Классы:
- 0 - 'левая верхняя часть лобового стекла',
- 1 - 'прямо перед собой',
- 2 - 'спидометр', 
- 3 - 'радио',
- 4 - 'правая верхняя часть лобового стекла',
- 5 - 'правая нижняя часть лобового стекла', 
- 6 - 'правое боковое зеркало', 
- 7 - 'зеркало заднего вида', 
- 8 - 'левое боковое зеркало'.

Точность модели на датасете <a href='https://sites.google.com/view/drivergazeprediction/home?pli=1'>DGW</a> составляет 65.85% и 64.19% на валидационной и тестовой выборках соответственно. Доступ к официальной тестовой выборке был утерян, поэтому она была получена из тренировочной выборки. Разделение кадров на 3 выборки представлено в директории dgw_annotation, там размещены .pickle файлы.

Ссылка на список экспериментов при обучении модели: https://docs.google.com/spreadsheets/d/1mxy4Okgb4FoaO_F6x-o7Jy1WDVrNDcsX8hAvSUKrdZg/edit?usp=sharing.

Протестировать можно по следующей ссылке: https://ai.m16.tech/api/cnn_based_driver_gaze_predictor?image_path=https://disk.yandex.ru/i/gzOQr0EMeagXtw
где https://disk.yandex.ru/i/gzOQr0EMeagXtw - путь к изображению на яндекс диске. Доступ к изображению должен быть открыт к чтению для всех, у кого есть ссылка.

Данная модель очень чувствительна к ракурсу, с которого сделан снимок. Ее точность напрямую зависит от местоположения камеры. Для получения оптимальной точности распознавания камеру следует расположить примерно так же, как в датасете DGW или на GIF-ке выше.